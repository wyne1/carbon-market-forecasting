{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "536c6b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import psycopg2\n",
    "from psycopg2.extras import RealDictCursor\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "import gmail_api\n",
    "import base64\n",
    "import email\n",
    "from email.mime.text import MIMEText\n",
    "from email.mime.multipart import MIMEMultipart\n",
    "from email.mime.base import MIMEBase\n",
    "from email import encoders\n",
    "import io\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25dbd792",
   "metadata": {},
   "outputs": [],
   "source": [
    "EQUITY_BASE = 'S3121200 - Equity Base'\n",
    "WPAC_STATEMENT = 'Wpac Statement data'\n",
    "\n",
    "trading_account = pd.read_excel('Wentworth Stock & Trading Futures Account.xls', sheet_name=EQUITY_BASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "951b5365",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Business Date (Start)</th>\n",
       "      <th>Starting Cash</th>\n",
       "      <th>Daily Charges</th>\n",
       "      <th>Profit and Loss</th>\n",
       "      <th>Daily Transfers</th>\n",
       "      <th>Daily Received Cash</th>\n",
       "      <th>Daily Cash Paid</th>\n",
       "      <th>Cash</th>\n",
       "      <th>Open Trade Equity</th>\n",
       "      <th>Total Equity</th>\n",
       "      <th>...</th>\n",
       "      <th>YTD Profit and Loss</th>\n",
       "      <th>Gross Trading P&amp;L</th>\n",
       "      <th>Net Trading P&amp;L</th>\n",
       "      <th>Open Trade Equity</th>\n",
       "      <th>Daily Futures P&amp;L</th>\n",
       "      <th>Drawdown (Total FUM)</th>\n",
       "      <th>Margin Utilsation</th>\n",
       "      <th>FUM</th>\n",
       "      <th>Wpac BizOne</th>\n",
       "      <th>Wpac Cash Reserve</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>2025-08-27</td>\n",
       "      <td>842333.63</td>\n",
       "      <td>-75.08</td>\n",
       "      <td>-5220.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>837038.49</td>\n",
       "      <td>0.00</td>\n",
       "      <td>837038.49</td>\n",
       "      <td>...</td>\n",
       "      <td>-6828.98</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-75.08</td>\n",
       "      <td>3512.22</td>\n",
       "      <td>3437.14</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>888971.79</td>\n",
       "      <td>25159</td>\n",
       "      <td>26774.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>2025-08-28</td>\n",
       "      <td>837029.81</td>\n",
       "      <td>-150.22</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>836879.59</td>\n",
       "      <td>-715.34</td>\n",
       "      <td>836164.25</td>\n",
       "      <td>...</td>\n",
       "      <td>-6831.47</td>\n",
       "      <td>-715.34</td>\n",
       "      <td>-865.56</td>\n",
       "      <td>-715.34</td>\n",
       "      <td>-1580.90</td>\n",
       "      <td>-0.000827</td>\n",
       "      <td>0.060191</td>\n",
       "      <td>864592.89</td>\n",
       "      <td>939</td>\n",
       "      <td>26774.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>2025-08-29</td>\n",
       "      <td>836878.53</td>\n",
       "      <td>-25.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>836853.51</td>\n",
       "      <td>14565.15</td>\n",
       "      <td>851418.66</td>\n",
       "      <td>...</td>\n",
       "      <td>-6826.86</td>\n",
       "      <td>14565.15</td>\n",
       "      <td>14540.13</td>\n",
       "      <td>15280.49</td>\n",
       "      <td>29820.62</td>\n",
       "      <td>0.016846</td>\n",
       "      <td>0.070176</td>\n",
       "      <td>864581.56</td>\n",
       "      <td>939</td>\n",
       "      <td>26789.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>2025-09-01</td>\n",
       "      <td>836850.52</td>\n",
       "      <td>-150.12</td>\n",
       "      <td>18586.48</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>855286.88</td>\n",
       "      <td>10168.95</td>\n",
       "      <td>865455.83</td>\n",
       "      <td>...</td>\n",
       "      <td>11759.53</td>\n",
       "      <td>10168.95</td>\n",
       "      <td>10018.83</td>\n",
       "      <td>-4396.20</td>\n",
       "      <td>5622.63</td>\n",
       "      <td>0.011516</td>\n",
       "      <td>0.029448</td>\n",
       "      <td>883014.93</td>\n",
       "      <td>939</td>\n",
       "      <td>26789.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>2025-09-02</td>\n",
       "      <td>855286.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>855286.88</td>\n",
       "      <td>10168.95</td>\n",
       "      <td>865455.83</td>\n",
       "      <td>...</td>\n",
       "      <td>11759.53</td>\n",
       "      <td>10168.95</td>\n",
       "      <td>10168.95</td>\n",
       "      <td>0.00</td>\n",
       "      <td>10168.95</td>\n",
       "      <td>0.008598</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1182685.93</td>\n",
       "      <td>300610</td>\n",
       "      <td>26789.05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Business Date (Start)  Starting Cash  Daily Charges  Profit and Loss  \\\n",
       "302            2025-08-27      842333.63         -75.08         -5220.06   \n",
       "303            2025-08-28      837029.81        -150.22             0.00   \n",
       "304            2025-08-29      836878.53         -25.02             0.00   \n",
       "305            2025-09-01      836850.52        -150.12         18586.48   \n",
       "306            2025-09-02      855286.88           0.00             0.00   \n",
       "\n",
       "     Daily Transfers  Daily Received Cash  Daily Cash Paid       Cash  \\\n",
       "302              0.0                    0                0  837038.49   \n",
       "303              0.0                    0                0  836879.59   \n",
       "304              0.0                    0                0  836853.51   \n",
       "305              0.0                    0                0  855286.88   \n",
       "306              0.0                    0                0  855286.88   \n",
       "\n",
       "     Open Trade Equity  Total Equity  ...  YTD Profit and Loss  \\\n",
       "302               0.00     837038.49  ...             -6828.98   \n",
       "303            -715.34     836164.25  ...             -6831.47   \n",
       "304           14565.15     851418.66  ...             -6826.86   \n",
       "305           10168.95     865455.83  ...             11759.53   \n",
       "306           10168.95     865455.83  ...             11759.53   \n",
       "\n",
       "     Gross Trading P&L  Net Trading P&L  Open Trade Equity   \\\n",
       "302               0.00           -75.08             3512.22   \n",
       "303            -715.34          -865.56             -715.34   \n",
       "304           14565.15         14540.13            15280.49   \n",
       "305           10168.95         10018.83            -4396.20   \n",
       "306           10168.95         10168.95                0.00   \n",
       "\n",
       "     Daily Futures P&L  Drawdown (Total FUM)  Margin Utilsation          FUM  \\\n",
       "302            3437.14              0.000000            0.000000   888971.79   \n",
       "303           -1580.90             -0.000827            0.060191   864592.89   \n",
       "304           29820.62              0.016846            0.070176   864581.56   \n",
       "305            5622.63              0.011516            0.029448   883014.93   \n",
       "306           10168.95              0.008598            0.000000  1182685.93   \n",
       "\n",
       "     Wpac BizOne  Wpac Cash Reserve  \n",
       "302        25159           26774.30  \n",
       "303          939           26774.30  \n",
       "304          939           26789.05  \n",
       "305          939           26789.05  \n",
       "306       300610           26789.05  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trading_account.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b60b5fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Business Date (Start)', 'Starting Cash', 'Daily Charges',\n",
       "       'Profit and Loss', 'Daily Transfers', 'Daily Received Cash',\n",
       "       'Daily Cash Paid', 'Cash', 'Open Trade Equity', 'Total Equity',\n",
       "       'Net Liquidation Value', 'Initial Margin', 'Maintenance Margin',\n",
       "       'Excess Deficit', 'MTD Profit and Loss', 'YTD Profit and Loss',\n",
       "       'Gross Trading P&L', 'Net Trading P&L', 'Open Trade Equity ',\n",
       "       'Daily Futures P&L', 'Drawdown (Total FUM)', 'Margin Utilsation ',\n",
       "       'FUM', 'Wpac BizOne', 'Wpac Cash Reserve'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trading_account.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f81bb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Database Configuration\n",
    "DB_CONFIG = {\n",
    "    'host': 'localhost',\n",
    "    'port': 5432,\n",
    "    'user': 'zeerakwyne',\n",
    "    'password': '',\n",
    "    'database': 'wentworth'\n",
    "}\n",
    "\n",
    "# Gmail Configuration (you'll need to set these up)\n",
    "GMAIL_CREDENTIALS = {\n",
    "    'credentials_file': 'credentials.json',  # Download from Google Cloud Console\n",
    "    'token_file': 'token.json'  # Will be created after first auth\n",
    "}\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4840da8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-19 23:43:19,318 - INFO - Database 'wentworth' already exists\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_database():\n",
    "    \"\"\"Create the wentworth database if it doesn't exist\"\"\"\n",
    "    try:\n",
    "        # Connect to default postgres database to create wentworth\n",
    "        conn = psycopg2.connect(\n",
    "            host=DB_CONFIG['host'],\n",
    "            port=DB_CONFIG['port'],\n",
    "            user=DB_CONFIG['user'],\n",
    "            password=DB_CONFIG['password'],\n",
    "            database='postgres'  # Connect to default postgres db\n",
    "        )\n",
    "        conn.autocommit = True\n",
    "        cursor = conn.cursor()\n",
    "        \n",
    "        # Check if database exists\n",
    "        cursor.execute(\"SELECT 1 FROM pg_database WHERE datname = 'wentworth'\")\n",
    "        exists = cursor.fetchone()\n",
    "        \n",
    "        if not exists:\n",
    "            cursor.execute(\"CREATE DATABASE wentworth\")\n",
    "            logger.info(\"Database 'wentworth' created successfully\")\n",
    "        else:\n",
    "            logger.info(\"Database 'wentworth' already exists\")\n",
    "            \n",
    "        cursor.close()\n",
    "        conn.close()\n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error creating database: {e}\")\n",
    "        return False\n",
    "\n",
    "# Test database creation\n",
    "create_database()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9946a49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_excel_from_database_updated(output_file=None):\n",
    "    \"\"\"Generate Excel file from database data - Updated to match original format\"\"\"\n",
    "    try:\n",
    "        conn = psycopg2.connect(**DB_CONFIG)\n",
    "        \n",
    "        # Query all data from database\n",
    "        query = \"\"\"\n",
    "        SELECT \n",
    "            business_date, starting_cash, daily_charges, profit_and_loss, \n",
    "            daily_transfers, daily_received_cash, daily_cash_paid, cash, \n",
    "            open_trade_equity, total_equity, net_liquidation_value, \n",
    "            initial_margin, maintenance_margin, excess_deficit, \n",
    "            mtd_profit_and_loss, ytd_profit_and_loss\n",
    "        FROM equity_data \n",
    "        ORDER BY business_date DESC;\n",
    "        \"\"\"\n",
    "        \n",
    "        df = pd.read_sql_query(query, conn)\n",
    "        conn.close()\n",
    "        \n",
    "        # Rename columns to match original Excel format exactly\n",
    "        column_mapping = {\n",
    "            'business_date': 'Business Date (Start)',\n",
    "            'starting_cash': 'Starting Cash',\n",
    "            'daily_charges': 'Daily Charges',\n",
    "            'profit_and_loss': 'Profit and Loss',\n",
    "            'daily_transfers': 'Daily Transfers',\n",
    "            'daily_received_cash': 'Daily Received Cash',\n",
    "            'daily_cash_paid': 'Daily Cash Paid',\n",
    "            'cash': 'Cash',\n",
    "            'open_trade_equity': 'Open Trade Equity',\n",
    "            'total_equity': 'Total Equity',\n",
    "            'net_liquidation_value': 'Net Liquidation Value',\n",
    "            'initial_margin': 'Initial Margin',\n",
    "            'maintenance_margin': 'Maintenance Margin',\n",
    "            'excess_deficit': 'Excess Deficit',\n",
    "            'mtd_profit_and_loss': 'MTD Profit and Loss',\n",
    "            'ytd_profit_and_loss': 'YTD Profit and Loss'\n",
    "        }\n",
    "        \n",
    "        df = df.rename(columns=column_mapping)\n",
    "        \n",
    "        # Add the additional columns that are in the original Excel but not in our database\n",
    "        # These will be empty/NaN for now, but we can populate them later if needed\n",
    "        additional_columns = {\n",
    "            'Gross Trading P&L': df['Profit and Loss'],  # Same as Profit and Loss\n",
    "            'Net Trading P&L': df['Profit and Loss'],    # Same as Profit and Loss  \n",
    "            'Open Trade Equity ': df['Open Trade Equity'],  # Note the trailing space\n",
    "            'Daily Futures P&L': df['Profit and Loss']   # Same as Profit and Loss\n",
    "        }\n",
    "        \n",
    "        # Add the additional columns\n",
    "        for col_name, col_data in additional_columns.items():\n",
    "            df[col_name] = col_data\n",
    "        \n",
    "        # Reorder columns to match original Excel format\n",
    "        column_order = [\n",
    "            'Business Date (Start)', 'Starting Cash', 'Daily Charges', 'Profit and Loss',\n",
    "            'Daily Transfers', 'Daily Received Cash', 'Daily Cash Paid', 'Cash',\n",
    "            'Open Trade Equity', 'Total Equity', 'Net Liquidation Value', 'Initial Margin',\n",
    "            'Maintenance Margin', 'Excess Deficit', 'MTD Profit and Loss', 'YTD Profit and Loss',\n",
    "            'Gross Trading P&L', 'Net Trading P&L', 'Open Trade Equity ', 'Daily Futures P&L'\n",
    "        ]\n",
    "        \n",
    "        df = df[column_order]\n",
    "        \n",
    "        # Generate output filename if not provided\n",
    "        if output_file is None:\n",
    "            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "            output_file = f'../data/Wentworth_Stock_Trading_Futures_Account_{timestamp}.xlsx'\n",
    "        \n",
    "        # Create Excel file with multiple sheets\n",
    "        with pd.ExcelWriter(output_file, engine='openpyxl') as writer:\n",
    "            # Main equity data sheet\n",
    "            df.to_excel(writer, sheet_name=EQUITY_BASE, index=False)\n",
    "            \n",
    "            # Summary sheet\n",
    "            summary_data = {\n",
    "                'Total Records': [len(df)],\n",
    "                'Date Range': [f\"{df['Business Date (Start)'].min()} to {df['Business Date (Start)'].max()}\"],\n",
    "                'Last Updated': [datetime.now().strftime('%Y-%m-%d %H:%M:%S')],\n",
    "                'Account ID': ['S3121200'],\n",
    "                'Legal Account Name': ['WENTWORTH STOCK AND TRADING PTY LTD']\n",
    "            }\n",
    "            summary_df = pd.DataFrame(summary_data)\n",
    "            summary_df.to_excel(writer, sheet_name='Summary', index=False)\n",
    "        \n",
    "        logger.info(f\"Excel file generated successfully: {output_file}\")\n",
    "        return output_file\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error generating Excel file: {e}\")\n",
    "        return None\n",
    "\n",
    "# Test the updated Excel generation\n",
    "# generate_excel_from_database_updated()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "37296d1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-19 23:43:20,906 - INFO - Equity data table created successfully\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_equity_table():\n",
    "    \"\"\"Create the equity_data table with proper schema\"\"\"\n",
    "    try:\n",
    "        conn = psycopg2.connect(**DB_CONFIG)\n",
    "        cursor = conn.cursor()\n",
    "        \n",
    "        # Create table with all columns from CSV\n",
    "        create_table_query = \"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS equity_data (\n",
    "            id SERIAL PRIMARY KEY,\n",
    "            business_date DATE NOT NULL,\n",
    "            managing_location VARCHAR(50),\n",
    "            account_id VARCHAR(50),\n",
    "            family_group_code_1 VARCHAR(50),\n",
    "            legal_account_name VARCHAR(255),\n",
    "            currency VARCHAR(10),\n",
    "            starting_cash DECIMAL(15,2),\n",
    "            daily_charges DECIMAL(15,2),\n",
    "            daily_tax DECIMAL(15,2),\n",
    "            daily_option_premiums DECIMAL(15,2),\n",
    "            profit_and_loss DECIMAL(15,2),\n",
    "            daily_transfers DECIMAL(15,2),\n",
    "            daily_received_cash DECIMAL(15,2),\n",
    "            daily_cash_paid DECIMAL(15,2),\n",
    "            cash DECIMAL(15,2),\n",
    "            open_trade_equity DECIMAL(15,2),\n",
    "            total_equity DECIMAL(15,2),\n",
    "            net_option_value DECIMAL(15,2),\n",
    "            net_liquidation_value DECIMAL(15,2),\n",
    "            initial_margin DECIMAL(15,2),\n",
    "            maintenance_margin DECIMAL(15,2),\n",
    "            excess_deficit DECIMAL(15,2),\n",
    "            mtd_profit_and_loss DECIMAL(15,2),\n",
    "            ytd_profit_and_loss DECIMAL(15,2),\n",
    "            forward_cash_entries DECIMAL(15,2),\n",
    "            forward_futures_pl DECIMAL(15,2),\n",
    "            forward_charges DECIMAL(15,2),\n",
    "            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n",
    "            UNIQUE(business_date, account_id)\n",
    "        );\n",
    "        \"\"\"\n",
    "        \n",
    "        cursor.execute(create_table_query)\n",
    "        \n",
    "        # Create index on business_date for efficient querying\n",
    "        cursor.execute(\"CREATE INDEX IF NOT EXISTS idx_equity_business_date ON equity_data(business_date);\")\n",
    "        cursor.execute(\"CREATE INDEX IF NOT EXISTS idx_equity_account_id ON equity_data(account_id);\")\n",
    "        \n",
    "        conn.commit()\n",
    "        cursor.close()\n",
    "        conn.close()\n",
    "        \n",
    "        logger.info(\"Equity data table created successfully\")\n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error creating equity table: {e}\")\n",
    "        return False\n",
    "\n",
    "# Create the table\n",
    "create_equity_table()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c0c56f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-19 23:43:21,898 - INFO - Loaded 307 rows from Excel file\n",
      "2025-10-19 23:43:21,899 - INFO - Columns: ['Business Date (Start)', 'Starting Cash', 'Daily Charges', 'Profit and Loss', 'Daily Transfers', 'Daily Received Cash', 'Daily Cash Paid', 'Cash', 'Open Trade Equity', 'Total Equity', 'Net Liquidation Value', 'Initial Margin', 'Maintenance Margin', 'Excess Deficit', 'MTD Profit and Loss', 'YTD Profit and Loss', 'Gross Trading P&L', 'Net Trading P&L', 'Open Trade Equity ', 'Daily Futures P&L', 'Drawdown (Total FUM)', 'Margin Utilsation ', 'FUM', 'Wpac BizOne', 'Wpac Cash Reserve']\n",
      "2025-10-19 23:43:21,900 - INFO - After cleaning: 307 rows\n",
      "2025-10-19 23:43:21,973 - INFO - Successfully migrated 331 records to database\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Let's examine the actual Excel file structure\n",
    "# excel_file = '../data/Wentworth Stock & Trading Futures Account.xls'\n",
    "# df_excel = pd.read_excel(excel_file, sheet_name=EQUITY_BASE)\n",
    "\n",
    "# print(\"Excel file shape:\", df_excel.shape)\n",
    "# print(\"\\nColumn names:\")\n",
    "# print(df_excel.columns.tolist())\n",
    "# print(\"\\nFirst few rows:\")\n",
    "# print(df_excel.head())\n",
    "# print(\"\\nData types:\")\n",
    "# print(df_excel.dtypes)\n",
    "\n",
    "\n",
    "def migrate_excel_to_database_fixed():\n",
    "    \"\"\"Migrate existing Excel data to PostgreSQL database - FIXED VERSION\"\"\"\n",
    "    try:\n",
    "        # Read the existing Excel file\n",
    "        excel_file = 'Wentworth Stock & Trading Futures Account.xls'\n",
    "        df = pd.read_excel(excel_file, sheet_name=EQUITY_BASE)\n",
    "        \n",
    "        logger.info(f\"Loaded {len(df)} rows from Excel file\")\n",
    "        logger.info(f\"Columns: {df.columns.tolist()}\")\n",
    "        \n",
    "        # Clean the data - remove rows with null business dates\n",
    "        df_clean = df.dropna(subset=['Business Date (Start)'])\n",
    "        logger.info(f\"After cleaning: {len(df_clean)} rows\")\n",
    "        \n",
    "        # Connect to database\n",
    "        conn = psycopg2.connect(**DB_CONFIG)\n",
    "        cursor = conn.cursor()\n",
    "        \n",
    "        # Prepare data for insertion - mapping Excel columns to database columns\n",
    "        insert_query = \"\"\"\n",
    "        INSERT INTO equity_data (\n",
    "            business_date, managing_location, account_id, family_group_code_1, \n",
    "            legal_account_name, currency, starting_cash, daily_charges, daily_tax,\n",
    "            daily_option_premiums, profit_and_loss, daily_transfers, daily_received_cash,\n",
    "            daily_cash_paid, cash, open_trade_equity, total_equity, net_option_value,\n",
    "            net_liquidation_value, initial_margin, maintenance_margin, excess_deficit,\n",
    "            mtd_profit_and_loss, ytd_profit_and_loss, forward_cash_entries,\n",
    "            forward_futures_pl, forward_charges\n",
    "        ) VALUES (\n",
    "            %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s\n",
    "        ) ON CONFLICT (business_date, account_id) DO NOTHING;\n",
    "        \"\"\"\n",
    "        \n",
    "        # Convert DataFrame to list of tuples with proper mapping\n",
    "        data_tuples = []\n",
    "        for _, row in df_clean.iterrows():\n",
    "            # Map Excel columns to database columns\n",
    "            data_tuple = (\n",
    "                row.get('Business Date (Start)'),  # business_date\n",
    "                'SINSFT',  # managing_location (default value)\n",
    "                'S3121200',  # account_id (default value)\n",
    "                None,  # family_group_code_1\n",
    "                'WENTWORTH STOCK AND TRADING PTY LTD',  # legal_account_name (default value)\n",
    "                'AUD',  # currency (default value)\n",
    "                row.get('Starting Cash'),  # starting_cash\n",
    "                row.get('Daily Charges'),  # daily_charges\n",
    "                None,  # daily_tax\n",
    "                None,  # daily_option_premiums\n",
    "                row.get('Profit and Loss'),  # profit_and_loss\n",
    "                row.get('Daily Transfers'),  # daily_transfers\n",
    "                row.get('Daily Received Cash'),  # daily_received_cash\n",
    "                row.get('Daily Cash Paid'),  # daily_cash_paid\n",
    "                row.get('Cash'),  # cash\n",
    "                row.get('Open Trade Equity'),  # open_trade_equity\n",
    "                row.get('Total Equity'),  # total_equity\n",
    "                None,  # net_option_value\n",
    "                row.get('Net Liquidation Value'),  # net_liquidation_value\n",
    "                row.get('Initial Margin'),  # initial_margin\n",
    "                row.get('Maintenance Margin'),  # maintenance_margin\n",
    "                row.get('Excess Deficit'),  # excess_deficit\n",
    "                row.get('MTD Profit and Loss'),  # mtd_profit_and_loss\n",
    "                row.get('YTD Profit and Loss'),  # ytd_profit_and_loss\n",
    "                None,  # forward_cash_entries\n",
    "                None,  # forward_futures_pl\n",
    "                None   # forward_charges\n",
    "            )\n",
    "            data_tuples.append(data_tuple)\n",
    "        \n",
    "        # Insert data\n",
    "        cursor.executemany(insert_query, data_tuples)\n",
    "        conn.commit()\n",
    "        \n",
    "        # Get count of inserted records\n",
    "        cursor.execute(\"SELECT COUNT(*) FROM equity_data\")\n",
    "        count = cursor.fetchone()[0]\n",
    "        \n",
    "        cursor.close()\n",
    "        conn.close()\n",
    "        \n",
    "        logger.info(f\"Successfully migrated {count} records to database\")\n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error migrating Excel data: {e}\")\n",
    "        return False\n",
    "\n",
    "# Migrate the data with the fixed function\n",
    "migrate_excel_to_database_fixed()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ba3864cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-19 23:43:25,612 - INFO - file_cache is only supported with oauth2client<4.0.0\n",
      "2025-10-19 23:43:25,618 - INFO - Gmail API authenticated successfully\n",
      "2025-10-19 23:43:25,619 - INFO - Gmail API setup successful\n"
     ]
    }
   ],
   "source": [
    "def setup_gmail_api():\n",
    "    \"\"\"Initialize Gmail API connection\"\"\"\n",
    "    try:\n",
    "        from gmail_api import GmailAPI\n",
    "        gmail = GmailAPI(\n",
    "            credentials_file='../credentials.json',\n",
    "            token_file='../token.json'\n",
    "        )\n",
    "        logger.info(\"Gmail API setup successful\")\n",
    "        return gmail\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error setting up Gmail API: {e}\")\n",
    "        return None\n",
    "\n",
    "# Initialize Gmail API (you'll need to set up credentials first)\n",
    "gmail = setup_gmail_api()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b09431de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_csv_data(csv_content):\n",
    "    \"\"\"Process CSV content and return DataFrame\"\"\"\n",
    "    try:\n",
    "        from io import StringIO\n",
    "        df = pd.read_csv(StringIO(csv_content))\n",
    "        \n",
    "        # Clean column names (remove spaces, convert to lowercase)\n",
    "        df.columns = df.columns.str.replace(' ', '_').str.lower()\n",
    "        \n",
    "        # Convert Business Date to datetime\n",
    "        df['business_date'] = pd.to_datetime(df['business_date'])\n",
    "        \n",
    "        logger.info(f\"Processed CSV with {len(df)} rows\")\n",
    "        return df\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error processing CSV data: {e}\")\n",
    "        return None\n",
    "\n",
    "def insert_csv_to_database(df):\n",
    "    \"\"\"Insert CSV data into database\"\"\"\n",
    "    try:\n",
    "        conn = psycopg2.connect(**DB_CONFIG)\n",
    "        cursor = conn.cursor()\n",
    "        \n",
    "        # Prepare data for insertion\n",
    "        insert_query = \"\"\"\n",
    "        INSERT INTO equity_data (\n",
    "            business_date, managing_location, account_id, family_group_code_1, \n",
    "            legal_account_name, currency, starting_cash, daily_charges, daily_tax,\n",
    "            daily_option_premiums, profit_and_loss, daily_transfers, daily_received_cash,\n",
    "            daily_cash_paid, cash, open_trade_equity, total_equity, net_option_value,\n",
    "            net_liquidation_value, initial_margin, maintenance_margin, excess_deficit,\n",
    "            mtd_profit_and_loss, ytd_profit_and_loss, forward_cash_entries,\n",
    "            forward_futures_pl, forward_charges\n",
    "        ) VALUES (\n",
    "            %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s\n",
    "        ) ON CONFLICT (business_date, account_id) DO UPDATE SET\n",
    "            managing_location = EXCLUDED.managing_location,\n",
    "            family_group_code_1 = EXCLUDED.family_group_code_1,\n",
    "            legal_account_name = EXCLUDED.legal_account_name,\n",
    "            currency = EXCLUDED.currency,\n",
    "            starting_cash = EXCLUDED.starting_cash,\n",
    "            daily_charges = EXCLUDED.daily_charges,\n",
    "            daily_tax = EXCLUDED.daily_tax,\n",
    "            daily_option_premiums = EXCLUDED.daily_option_premiums,\n",
    "            profit_and_loss = EXCLUDED.profit_and_loss,\n",
    "            daily_transfers = EXCLUDED.daily_transfers,\n",
    "            daily_received_cash = EXCLUDED.daily_received_cash,\n",
    "            daily_cash_paid = EXCLUDED.daily_cash_paid,\n",
    "            cash = EXCLUDED.cash,\n",
    "            open_trade_equity = EXCLUDED.open_trade_equity,\n",
    "            total_equity = EXCLUDED.total_equity,\n",
    "            net_option_value = EXCLUDED.net_option_value,\n",
    "            net_liquidation_value = EXCLUDED.net_liquidation_value,\n",
    "            initial_margin = EXCLUDED.initial_margin,\n",
    "            maintenance_margin = EXCLUDED.maintenance_margin,\n",
    "            excess_deficit = EXCLUDED.excess_deficit,\n",
    "            mtd_profit_and_loss = EXCLUDED.mtd_profit_and_loss,\n",
    "            ytd_profit_and_loss = EXCLUDED.ytd_profit_and_loss,\n",
    "            forward_cash_entries = EXCLUDED.forward_cash_entries,\n",
    "            forward_futures_pl = EXCLUDED.forward_futures_pl,\n",
    "            forward_charges = EXCLUDED.forward_charges,\n",
    "            created_at = CURRENT_TIMESTAMP;\n",
    "        \"\"\"\n",
    "        \n",
    "        # Convert DataFrame to list of tuples\n",
    "        data_tuples = []\n",
    "        for _, row in df.iterrows():\n",
    "            data_tuple = (\n",
    "                row.get('business_date'),\n",
    "                row.get('managing_location'),\n",
    "                row.get('account_id'),\n",
    "                row.get('family_group_code_1'),\n",
    "                row.get('legal_account_name'),\n",
    "                row.get('currency'),\n",
    "                row.get('starting_cash'),\n",
    "                row.get('daily_charges'),\n",
    "                row.get('daily_tax'),\n",
    "                row.get('daily_option_premiums'),\n",
    "                row.get('profit_and_loss'),\n",
    "                row.get('daily_transfers'),\n",
    "                row.get('daily_received_cash'),\n",
    "                row.get('daily_cash_paid'),\n",
    "                row.get('cash'),\n",
    "                row.get('open_trade_equity'),\n",
    "                row.get('total_equity'),\n",
    "                row.get('net_option_value'),\n",
    "                row.get('net_liquidation_value'),\n",
    "                row.get('initial_margin'),\n",
    "                row.get('maintenance_margin'),\n",
    "                row.get('excess_deficit'),\n",
    "                row.get('mtd_profit_and_loss'),\n",
    "                row.get('ytd_profit_and_loss'),\n",
    "                row.get('forward_cash_entries'),\n",
    "                row.get('forward_futures_pl'),\n",
    "                row.get('forward_charges')\n",
    "            )\n",
    "            data_tuples.append(data_tuple)\n",
    "        \n",
    "        # Insert data\n",
    "        cursor.executemany(insert_query, data_tuples)\n",
    "        conn.commit()\n",
    "        \n",
    "        cursor.close()\n",
    "        conn.close()\n",
    "        \n",
    "        logger.info(f\"Successfully inserted {len(data_tuples)} records to database\")\n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error inserting CSV data: {e}\")\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2b470ae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-19 23:43:29,321 - INFO - file_cache is only supported with oauth2client<4.0.0\n",
      "2025-10-19 23:43:29,323 - INFO - Gmail API authenticated successfully\n",
      "2025-10-19 23:43:29,323 - INFO - Gmail API setup successful\n",
      "2025-10-19 23:43:29,955 - INFO - Found 1 emails matching query: subject:\"TIDS3121200 Equity 20250926\"\n",
      "2025-10-19 23:43:30,210 - INFO - Found 0 emails matching query: subject:\"TIDS3121200 Equity 20250927\"\n",
      "2025-10-19 23:43:30,487 - INFO - Found 0 emails matching query: subject:\"TIDS3121200 Equity 20250928\"\n",
      "2025-10-19 23:43:30,746 - INFO - Found 1 emails matching query: subject:\"TIDS3121200 Equity 20250929\"\n",
      "2025-10-19 23:43:31,012 - INFO - Found 1 emails matching query: subject:\"TIDS3121200 Equity 20250930\"\n",
      "2025-10-19 23:43:31,262 - INFO - Found 1 emails matching query: subject:\"TIDS3121200 Equity 20251001\"\n",
      "2025-10-19 23:43:31,537 - INFO - Found 1 emails matching query: subject:\"TIDS3121200 Equity 20251002\"\n",
      "2025-10-19 23:43:31,801 - INFO - Found 1 emails matching query: subject:\"TIDS3121200 Equity 20251003\"\n",
      "2025-10-19 23:43:32,060 - INFO - Found 0 emails matching query: subject:\"TIDS3121200 Equity 20251004\"\n",
      "2025-10-19 23:43:32,329 - INFO - Found 0 emails matching query: subject:\"TIDS3121200 Equity 20251005\"\n",
      "2025-10-19 23:43:32,584 - INFO - Found 1 emails matching query: subject:\"TIDS3121200 Equity 20251006\"\n",
      "2025-10-19 23:43:32,852 - INFO - Found 1 emails matching query: subject:\"TIDS3121200 Equity 20251007\"\n",
      "2025-10-19 23:43:33,106 - INFO - Found 1 emails matching query: subject:\"TIDS3121200 Equity 20251008\"\n",
      "2025-10-19 23:43:33,356 - INFO - Found 1 emails matching query: subject:\"TIDS3121200 Equity 20251009\"\n",
      "2025-10-19 23:43:33,630 - INFO - Found 1 emails matching query: subject:\"TIDS3121200 Equity 20251010\"\n",
      "2025-10-19 23:43:34,549 - INFO - Processed CSV with 1 rows\n",
      "2025-10-19 23:43:34,558 - INFO - Successfully inserted 1 records to database\n",
      "2025-10-19 23:43:34,559 - INFO - Successfully processed email for 20250926\n",
      "2025-10-19 23:43:35,232 - INFO - Processed CSV with 1 rows\n",
      "2025-10-19 23:43:35,241 - INFO - Successfully inserted 1 records to database\n",
      "2025-10-19 23:43:35,242 - INFO - Successfully processed email for 20250929\n",
      "2025-10-19 23:43:35,907 - INFO - Processed CSV with 1 rows\n",
      "2025-10-19 23:43:35,919 - INFO - Successfully inserted 1 records to database\n",
      "2025-10-19 23:43:35,920 - INFO - Successfully processed email for 20250930\n",
      "2025-10-19 23:43:36,588 - INFO - Processed CSV with 1 rows\n",
      "2025-10-19 23:43:36,598 - INFO - Successfully inserted 1 records to database\n",
      "2025-10-19 23:43:36,598 - INFO - Successfully processed email for 20251001\n",
      "2025-10-19 23:43:37,186 - INFO - Processed CSV with 1 rows\n",
      "2025-10-19 23:43:37,195 - INFO - Successfully inserted 1 records to database\n",
      "2025-10-19 23:43:37,196 - INFO - Successfully processed email for 20251002\n",
      "2025-10-19 23:43:37,880 - INFO - Processed CSV with 1 rows\n",
      "2025-10-19 23:43:37,893 - INFO - Successfully inserted 1 records to database\n",
      "2025-10-19 23:43:37,894 - INFO - Successfully processed email for 20251003\n",
      "2025-10-19 23:43:38,469 - INFO - Processed CSV with 1 rows\n",
      "2025-10-19 23:43:38,481 - INFO - Successfully inserted 1 records to database\n",
      "2025-10-19 23:43:38,482 - INFO - Successfully processed email for 20251006\n",
      "2025-10-19 23:43:39,101 - INFO - Processed CSV with 1 rows\n",
      "2025-10-19 23:43:39,110 - INFO - Successfully inserted 1 records to database\n",
      "2025-10-19 23:43:39,110 - INFO - Successfully processed email for 20251007\n",
      "2025-10-19 23:43:39,922 - INFO - Processed CSV with 1 rows\n",
      "2025-10-19 23:43:39,930 - INFO - Successfully inserted 1 records to database\n",
      "2025-10-19 23:43:39,930 - INFO - Successfully processed email for 20251008\n",
      "2025-10-19 23:43:40,518 - INFO - Processed CSV with 1 rows\n",
      "2025-10-19 23:43:40,534 - INFO - Successfully inserted 1 records to database\n",
      "2025-10-19 23:43:40,535 - INFO - Successfully processed email for 20251009\n",
      "2025-10-19 23:43:41,196 - INFO - Processed CSV with 1 rows\n",
      "2025-10-19 23:43:41,214 - INFO - Successfully inserted 1 records to database\n",
      "2025-10-19 23:43:41,215 - INFO - Successfully processed email for 20251010\n",
      "2025-10-19 23:43:41,216 - INFO - Successfully processed 11 out of 11 emails\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def download_emails_by_date_range(start_date, end_date):\n",
    "    \"\"\"Download emails for a date range and process them\"\"\"\n",
    "    try:\n",
    "        gmail = setup_gmail_api()\n",
    "        if not gmail:\n",
    "            logger.error(\"Failed to setup Gmail API\")\n",
    "            return False\n",
    "        \n",
    "        # Convert string dates to datetime objects\n",
    "        if isinstance(start_date, str):\n",
    "            start_date = datetime.strptime(start_date, '%Y-%m-%d')\n",
    "        if isinstance(end_date, str):\n",
    "            end_date = datetime.strptime(end_date, '%Y-%m-%d')\n",
    "        \n",
    "        # Get emails for date range\n",
    "        emails = gmail.get_emails_by_date_range(start_date, end_date)\n",
    "        \n",
    "        if not emails:\n",
    "            logger.warning(f\"No emails found for date range {start_date} to {end_date}\")\n",
    "            return False\n",
    "        \n",
    "        success_count = 0\n",
    "        for date_str, message in emails:\n",
    "            try:\n",
    "                # Download CSV data\n",
    "                csv_data = gmail.download_csv_attachment(message['id'])\n",
    "                if csv_data:\n",
    "                    # Process CSV\n",
    "                    df = process_csv_data(csv_data.decode('utf-8'))\n",
    "                    if df is not None:\n",
    "                        # Insert to database\n",
    "                        if insert_csv_to_database(df):\n",
    "                            success_count += 1\n",
    "                            logger.info(f\"Successfully processed email for {date_str}\")\n",
    "                        else:\n",
    "                            logger.error(f\"Failed to insert data for {date_str}\")\n",
    "                    else:\n",
    "                        logger.error(f\"Failed to process CSV for {date_str}\")\n",
    "                else:\n",
    "                    logger.error(f\"No CSV data found for {date_str}\")\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error processing email for {date_str}: {e}\")\n",
    "        \n",
    "        logger.info(f\"Successfully processed {success_count} out of {len(emails)} emails\")\n",
    "        return success_count > 0\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error downloading emails: {e}\")\n",
    "        return False\n",
    "\n",
    "# Example usage:\n",
    "download_emails_by_date_range('2025-09-26', '2025-10-10')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67243f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def daily_automation():\n",
    "    \"\"\"Daily automation script to download today's email and update database\"\"\"\n",
    "    try:\n",
    "        logger.info(\"Starting daily automation process...\")\n",
    "        \n",
    "        # Get today's date\n",
    "        today = datetime.now().strftime('%Y%m%d')\n",
    "        today_date = datetime.now().strftime('%Y-%m-%d')\n",
    "        \n",
    "        logger.info(f\"Processing data for {today_date}\")\n",
    "        \n",
    "        # Setup Gmail API\n",
    "        gmail = setup_gmail_api()\n",
    "        if not gmail:\n",
    "            logger.error(\"Failed to setup Gmail API\")\n",
    "            return False\n",
    "        \n",
    "        # Download today's email\n",
    "        csv_data = gmail.get_daily_equity_data(today)\n",
    "        if not csv_data:\n",
    "            logger.warning(f\"No email found for today ({today_date})\")\n",
    "            return False\n",
    "        \n",
    "        # Process CSV data\n",
    "        df = process_csv_data(csv_data)\n",
    "        if df is None:\n",
    "            logger.error(\"Failed to process CSV data\")\n",
    "            return False\n",
    "        \n",
    "        # Insert to database\n",
    "        if not insert_csv_to_database(df):\n",
    "            logger.error(\"Failed to insert data to database\")\n",
    "            return False\n",
    "        \n",
    "        # Generate updated Excel file\n",
    "        excel_file = generate_excel_from_database()\n",
    "        if not excel_file:\n",
    "            logger.error(\"Failed to generate Excel file\")\n",
    "            return False\n",
    "        \n",
    "        logger.info(f\"Daily automation completed successfully. Excel file: {excel_file}\")\n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in daily automation: {e}\")\n",
    "        return False\n",
    "\n",
    "# Run daily automation\n",
    "daily_automation()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8979ee7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_database_stats():\n",
    "    \"\"\"Get statistics about the database\"\"\"\n",
    "    try:\n",
    "        conn = psycopg2.connect(**DB_CONFIG)\n",
    "        cursor = conn.cursor()\n",
    "        \n",
    "        # Get total count\n",
    "        cursor.execute(\"SELECT COUNT(*) FROM equity_data\")\n",
    "        total_count = cursor.fetchone()[0]\n",
    "        \n",
    "        # Get date range\n",
    "        cursor.execute(\"SELECT MIN(business_date), MAX(business_date) FROM equity_data\")\n",
    "        date_range = cursor.fetchone()\n",
    "        \n",
    "        # Get latest record\n",
    "        cursor.execute(\"SELECT business_date, account_id, total_equity FROM equity_data ORDER BY business_date DESC LIMIT 1\")\n",
    "        latest_record = cursor.fetchone()\n",
    "        \n",
    "        cursor.close()\n",
    "        conn.close()\n",
    "        \n",
    "        stats = {\n",
    "            'total_records': total_count,\n",
    "            'date_range': date_range,\n",
    "            'latest_record': latest_record\n",
    "        }\n",
    "        \n",
    "        logger.info(f\"Database Stats: {stats}\")\n",
    "        return stats\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error getting database stats: {e}\")\n",
    "        return None\n",
    "\n",
    "# Get database statistics\n",
    "get_database_stats()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb78061",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_database_stats()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "forecasting",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
