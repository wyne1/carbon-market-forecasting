{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "import IPython\n",
    "import pandas as pd\n",
    "from pandas import Series\n",
    "import numpy as np\n",
    "from random import randrange\n",
    "from matplotlib import pyplot\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "import math\n",
    "from typing import Any, List, Dict, AnyStr, Optional\n",
    "from pathlib import Path\n",
    "from glob import glob\n",
    "from utils.dataset import MarketData, DataPreprocessor, Plotting\n",
    "from utils.windowgenerator import WindowGenerator, compile_and_fit\n",
    "import tensorflow as tf\n",
    "import talib\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "eua_options_cols = ['Date', 'Aggregate Put Open Interest  (R1)', 'Aggregate Call Open Interest  (R1)', \n",
    "                    'Aggregate Open Interest  (L1)', 'OPTION OI%', 'PUT/CALL OI']\n",
    "eua_options = pd.read_excel('../data/data_sheet_latest.xlsx', sheet_name='EUA option-G363')\n",
    "eua_options['Date'] = pd.to_datetime(pd.to_datetime(eua_options['Date']).dt.date)\n",
    "eua_options = eua_options[eua_options_cols][eua_options['Date'].dt.year >= 2018].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(eua_options.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(eua_options.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pachis_delta = pd.read_excel('../data/data_sheet_latest.xlsx', sheet_name='25Delta')\n",
    "dec_cols = [\"Date\", \"Hist Vol\", \"50D-Hist Vol\", \"50D\", \"25D Spread\", \"butterfly\"]\n",
    "pachis_delta_dec = pachis_delta[dec_cols]\n",
    "pachis_delta_dec.columns = [\"Date\", \"Hist Vol - 1Y\", \n",
    "                        \"iVol/Hist Vol Spread - Dec\", \n",
    "                        \"50 Delta iVol - Dec\", \n",
    "                        \"25Δ Risk Reversal (Call - Put) - Dec\", \n",
    "                        \"Butterfly - Dec\"]\n",
    "pachis_delta_dec['Date'] = pd.to_datetime(pachis_delta_dec['Date'])\n",
    "pachis_delta_dec = pachis_delta_dec[pachis_delta_dec['Date'].dt.year > 2018] \n",
    "for col in ['Hist Vol - 1Y', 'iVol/Hist Vol Spread - Dec', '50 Delta iVol - Dec']:\n",
    "    pachis_delta_dec.iloc[:, pachis_delta_dec.columns.get_loc(col)] = pachis_delta_dec[col].replace(' ', np.nan).astype(float)\n",
    "pachis_delta_dec.iloc[:, pachis_delta_dec.columns.get_loc('iVol/Hist Vol Spread - Dec')] = pachis_delta_dec['iVol/Hist Vol Spread - Dec'].astype(float)\n",
    "pachis_delta_dec.iloc[:, pachis_delta_dec.columns.get_loc('50 Delta iVol - Dec')] = pachis_delta_dec['50 Delta iVol - Dec'].astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_cols = [\"Date.1\", \"50D.1\", \"25D Spread.1\", \"butterfly.1\"]\n",
    "pachis_delta_prompt = pachis_delta[prompt_cols]\n",
    "pachis_delta_prompt.columns = [\"Date\", \"50 Delta iVol - Prompt\",\n",
    "                               \"25Δ Risk Reversal (Call - Put) - Prompt\",\n",
    "                               \"Butterfly - Prompt\"]\n",
    "pachis_delta_prompt['Date'] = pd.to_datetime(pachis_delta_prompt['Date'])\n",
    "pachis_delta_prompt = pachis_delta_prompt[pachis_delta_prompt['Date'].dt.year > 2018]\n",
    "# First convert any string values to numeric, handling spaces\n",
    "pachis_delta_prompt['50 Delta iVol - Prompt'] = pd.to_numeric(pachis_delta_prompt['50 Delta iVol - Prompt'].replace(' ', np.nan), errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "option_ts = pd.read_excel('../data/data_sheet_latest.xlsx', sheet_name='Option Time series')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create prompt dataframe\n",
    "cols = ['Date', 'Call_OI-Prompt', 'Put_OI-Prompt', 'Dec_OI', 'Call/Put', 'Option%']\n",
    "option_ts_prompt = option_ts[cols].copy()\n",
    "option_ts_prompt.columns = ['Date', 'Call_OI-Prompt', 'Put_OI-Prompt', 'Dec_OI', 'Call/Put-Prompt', 'Option%-Prompt']\n",
    "\n",
    "# Create december dataframe\n",
    "cols = ['Date', 'Call/Put.1', 'Option%.1']\n",
    "option_ts_dec = option_ts[cols].copy()\n",
    "option_ts_dec.columns = ['Date', 'Call/Put-Dec', 'Option%-Dec']\n",
    "\n",
    "# Merge the two dataframes on Date\n",
    "option_ts_combined = pd.merge(option_ts_prompt, option_ts_dec, on='Date', how='outer')\n",
    "option_ts_combined = option_ts_combined.sort_values(by='Date', ascending=False)\n",
    "option_ts_combined = option_ts_combined[:-74]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = eua_options.merge(pachis_delta_dec, on='Date', how='left')\\\n",
    "    .merge(pachis_delta_prompt, on='Date', how='left')\\\n",
    "    .merge(option_ts_combined, on='Date', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = combined_df[combined_df['Date'].dt.year>=2023][:-70]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import streamlit as st\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "from pymongo import MongoClient\n",
    "from datetime import datetime\n",
    "\n",
    "from utils.dataset import MarketData, DataPreprocessor\n",
    "from utils.data_processing import prepare_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_data():\n",
    "    cot_df, auction_df, options_df, ta_df, fundamentals_df = MarketData.latest(Path('../data'))\n",
    "    cot_df = cot_df.set_index('Date').resample('W', origin='end').mean().reset_index()\n",
    "    auction_df = auction_df.set_index('Date').resample('D').mean().reset_index()\n",
    "\n",
    "    auction_df = auction_df[7:]\n",
    "    # auction_df.loc[:, 'Premium/discount-settle'] = auction_df['Premium/discount-settle'].ffill()\n",
    "    auc_cols = ['Auc Price', 'Median Price', 'Cover Ratio', 'Spot Value', \n",
    "                'Auction Spot Diff', 'Median Spot Diff', 'Premium/discount-settle']\n",
    "    auction_df.loc[:, auc_cols] = auction_df[auc_cols].ffill()\n",
    "\n",
    "    merged_df = DataPreprocessor.engineer_auction_features(auction_df)\n",
    "    return merged_df, options_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df, options_df = load_and_preprocess_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "options_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import streamlit as st\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "from pymongo import MongoClient\n",
    "from datetime import datetime\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "from utils.dataset import MarketData, DataPreprocessor\n",
    "from utils.data_processing import prepare_data, reverse_normalize\n",
    "from utils.plotting import (display_performance_metrics, display_trade_log, plot_equity_curve, \n",
    "                            plot_model_results_with_trades, plot_recent_predictions, plot_ensemble_statistics, plot_ensemble_predictions_realtime)\n",
    "from utils.model_utils import create_model, train_model, generate_model_predictions, train_ensemble_models\n",
    "from utils.mongodb_utils import get_stored_predictions, setup_mongodb_connection, save_recent_predictions\n",
    "from utils.backtesting import backtest_model_with_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cot_df, auction_df, options_df, ta_df, fundamentals_df = MarketData.latest(Path('../data'))\n",
    "cot_df = cot_df.set_index('Date').resample('W', origin='end').mean().reset_index()\n",
    "auction_df = auction_df.set_index('Date').resample('D').mean().reset_index()\n",
    "\n",
    "auction_df = auction_df[7:]\n",
    "# auction_df.loc[:, 'Premium/discount-settle'] = auction_df['Premium/discount-settle'].ffill()\n",
    "auc_cols = ['Auc Price', 'Median Price', 'Cover Ratio', 'Spot Value', \n",
    "            'Auction Spot Diff', 'Median Spot Diff', 'Premium/discount-settle']\n",
    "auction_df.loc[:, auc_cols] = auction_df[auc_cols].ffill()\n",
    "\n",
    "merged_df = DataPreprocessor.engineer_auction_features(auction_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "dup_dates = options_df['Date'].value_counts()[:10].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dup_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options_df[options_df['Date'].isin(dup_dates)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_df = merged_df[['Date', 'Auc Price']].copy()\n",
    "options_df = options_df.merge(auc_df, how='inner')\n",
    "options_df = options_df.bfill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "options_df = options_df.set_index('Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options_df['Date'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data_and_train_model(merged_df):\n",
    "    train_df, test_df, val_df, preprocessor = prepare_data(merged_df)\n",
    "    num_features = len(test_df.columns)\n",
    "    OUT_STEPS = 7\n",
    "    model = create_model(num_features, OUT_STEPS)\n",
    "    history = train_model(model, train_df, val_df, test_df, preprocessor)\n",
    "    predictions_df, recent_preds, trend = generate_model_predictions(model, test_df)\n",
    "    \n",
    "    return model, preprocessor, test_df, predictions_df, recent_preds, trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df, val_df, preprocessor = prepare_data(options_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = len(test_df.columns)\n",
    "OUT_STEPS = 7\n",
    "model = create_model(num_features, OUT_STEPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = train_model(model, train_df, val_df, test_df, preprocessor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df, recent_preds, trend = generate_model_predictions(model, test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trade_log_df, performance_metrics, balance_history_df = backtest_model_with_metrics(\n",
    "                    model,\n",
    "                    test_df,\n",
    "                    7,\n",
    "                    7,\n",
    "    10000,\n",
    "    4 / 100.0,\n",
    "    2 / 100.0,\n",
    "    position_size_fraction=100 / 100.0,\n",
    "    risk_free_rate=1 / 100.0,\n",
    "    preprocessor=preprocessor\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_width = 7\n",
    "out_steps= 7\n",
    "initial_balance = 10000\n",
    "take_profit = 4 / 100.0\n",
    "stop_loss = 2 / 100.0\n",
    "position_size_fraction =100 / 100.0\n",
    "risk_free_rate=1 / 100.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = test_df.columns\n",
    "num_features = len(features)\n",
    "predictions = []\n",
    "\n",
    "# Initialize balance and trade log\n",
    "balance = initial_balance\n",
    "balance_history = []\n",
    "trade_log = []\n",
    "\n",
    "# For performance metrics\n",
    "returns = []\n",
    "equity_curve = [initial_balance]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions in steps of 'out_steps'\n",
    "for idx, i in enumerate(range(input_width, len(test_df) - out_steps + 1, out_steps)):\n",
    "    try:\n",
    "        inputs = test_df[i - input_width:i].values\n",
    "        inputs_reshaped = inputs.reshape((1, input_width, num_features))\n",
    "        preds = model.predict(inputs_reshaped)\n",
    "        predictions.append(preds[0])\n",
    "    except Exception as e:\n",
    "        print(f\"Prediction error at index {i}: {e}\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame for predictions\n",
    "predictions = np.concatenate(predictions, axis=0)\n",
    "pred_indices = test_df.index[input_width:input_width + len(predictions)]\n",
    "predictions_df = pd.DataFrame(predictions, columns=features, index=pred_indices)\n",
    "# Reverse normalize predictions and test data\n",
    "predictions_df = reverse_normalize(predictions_df, preprocessor.train_mean['Auc Price'], preprocessor.train_std['Auc Price'])\n",
    "test_df_denormalized = reverse_normalize(test_df.copy(), preprocessor.train_mean['Auc Price'], preprocessor.train_std['Auc Price'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, i in enumerate(range(input_width, len(test_df) - out_steps + 1, out_steps)):\n",
    "    entry_index = predictions_df.index[idx * out_steps]\n",
    "    entry_price = test_df_denormalized.loc[entry_index, 'Auc Price']\n",
    "    prev_index = entry_index - pd.Timedelta(days=1)\n",
    "    prev_price = test_df_denormalized.loc[prev_index, 'Auc Price'] if prev_index in test_df_denormalized.index else entry_price\n",
    "    print(f\"IDX: {idx} | i: {i}\")\n",
    "    print(f\"Entry Index: {entry_index} | Entry Price: {entry_price} | \")\n",
    "    print(f\"Prev Index: {prev_index} | Prev Price: {prev_price}\")\n",
    "    print()\n",
    "    if idx == 2: break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "forecasting",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
